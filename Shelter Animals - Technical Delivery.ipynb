{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b68787",
   "metadata": {},
   "source": [
    "# Shelter Animals - Technical Delivery\n",
    "\n",
    "I will briefly summarise the steps that I've taken and their respective outcomes. I've written this document with the README file in mind. It is aimed at giving data science recruiters and others who may be interested a quick glance of what the project entails. For a more detailed view I reference you to the Proposal, Data Preparation, Exploratory Data Analysis and Modelling notebooks in that order.\n",
    "\n",
    "- What kind of technologies or methodologies were used?\n",
    "- What were the brief outcomes of these steps?\n",
    "- How can I try out the final result?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d82c4e",
   "metadata": {},
   "source": [
    "# Shelter Animals: Project Overview\n",
    "\n",
    "- Created a tool that predicts how long it takes for cats and dogs to be adopted (Acc ~51%) based on 5 categories. \n",
    "- Researched the domain to get a greater understanding of potentially influential factors.\n",
    "- Merged intake and outcome datasets to extract length of stay.\n",
    "- Extracted features from the available data to qualify the importance potential adopters put on fur colour, gender, castration, breed and age.\n",
    "- Investigated correlations between adoption speed and other characteristics such as age, intake type, intake condition and animal type.\n",
    "- Optimised Decision Tree, Random Forest, K-Nearest Neighbor and Support Vector Machine Classification using GridSearchCV and feature selection to reach the best model.\n",
    "- Built a client facing API using flask.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce83b9",
   "metadata": {},
   "source": [
    "# Code and Resourced Used\n",
    "\n",
    "**Python version**: 3.7  \n",
    "**Packages**: pandas, numpy, matplotlib, seaborn, plotly, wordcloud, sklearn, time, datetime, dateutil, calendar, re  \n",
    "**For Web Framework Requirements**: `pip install -r requirements.txt`  \n",
    "**Flask Production**: https://medium.com/@nutanbhogendrasharma/deploy-machine-learning-model-with-flask-on-heroku-cd079b692b1d   \n",
    "**Technical Documentation**: https://www.youtube.com/watch?v=agHKuUoMwvY&list=PL2zq7klxX5ASFejJj80ob9ZAnBHdz5O1t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ef4f5",
   "metadata": {},
   "source": [
    "### Data Collection \n",
    "\n",
    "Combined the Austin Shelter Intake and Outcome datasets. For each animal we for the following information:\n",
    "\n",
    "- Animal ID\n",
    "- Animal Type\n",
    "- Breed\n",
    "- Color\n",
    "- Found Location\n",
    "- Date of Birth\n",
    "- Intake Name\n",
    "- Outcome Name\n",
    "- Intake DateTime\n",
    "- Outcome Datetime\n",
    "- Sex upon Intake\n",
    "- Sex upon Outcome\n",
    "- Age upon Intake\n",
    "- Age upon Outcome\n",
    "- Intake Type\n",
    "- Intake Condition\n",
    "- Outcome Type\n",
    "- Outcome Subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9df793",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "After merging the data I needed to clean it up and extract various information. I made the following changes:\n",
    "- Calculated Days in Shelter.\n",
    "- Bucketed the Days in Shelter into Adoption Speed groups. \n",
    "\n",
    "\n",
    "- Selected only cats and dogs that were adopted.\n",
    "- Removed rows with unknown gender.\n",
    "- Removed or corrected rows with typographical errors.\n",
    "- Renamed the Name column and filled missing names with `Unknown`. \n",
    "- Calculated Intake and Outcome age to have it in a consistent format.\n",
    "\n",
    "\n",
    "- Made columns for gender and sterilization intake/outcome from the Gender intake/outcome.\n",
    "- Made columns for fur colour based on the most commonly found colours, allowing for mixed colours.\n",
    "- Narrowed down the breeds to the most commonly found family names. For example: `Alaskan Husky` becomes `Husky`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5865d",
   "metadata": {},
   "source": [
    "### EDA\n",
    "I looked at the distributions of the data, the value counts of the categories and the influence the features have on the target variable. I used graphs and visualisations to draw conclusions from. Below are a few highlights. \n",
    "\n",
    "<img src='https://i.imgur.com/xHLFFW1.png' width=450px align=\"left\">\n",
    "<img src='https://i.imgur.com/4XFXDbz.png' width=450px align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00847636",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/OBZYo6O.png' width=450px align=\"left\">\n",
    "<img src='https://i.imgur.com/XOhicKJ.png' width=450px align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408e980",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "First I one hot encoded the categorical variables, label encoded the target variable and converted dates to categories for years, months, days and day of the week. To even out the weight of numerical values I scaled them using a MinMaxScaler. I also split the data into a training and testing (or validation) set with a test size of 20%.   \n",
    "\n",
    "I set the baseline of the models to the largest group, which was approximately equal to 23.5% of the total. I tried four different models and evaluated them through the accuracy of cross validation and the testing set. When more insights were necessary I used the classification report to look at the recall and precision or made use of the confusion matrix.\n",
    "\n",
    "The four models I tried were:\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. K-Nearest Neighbor\n",
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53349c4e",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The Random Forest model far outperformed the other approaches on the testing and validation sets. Below I've listed the scores of each model on the validation set.\n",
    "\n",
    "- **Decision Tree** : 44.92%\n",
    "- **Random Forest** : 51.00% \n",
    "- **K-Nearest Neighbor** : 40.06%\n",
    "- **Support Vector Machine** : 39.12% \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfe978",
   "metadata": {},
   "source": [
    "### Productionization\n",
    "To put the model into production I built a flask API endpoint that is hosted on a local webserver. I followed a tutorial that is listed in Code and Resourced used. The API endpoint takes a POST request in JSON format, then transforms and scales the data the same way I prepared the data during the Modelling stage. It afterwards returns the estimated time it takes for the animal to get adopted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
